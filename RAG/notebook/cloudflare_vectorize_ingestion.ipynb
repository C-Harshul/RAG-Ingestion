{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG pipeline (Cloudflare Workers AI + Vectorize)\n",
        "\n",
        "This notebook ingests PDF documents, chunks them, generates embeddings using Cloudflare Workers AI, and stores vectors in Cloudflare Vectorize.\n",
        "\n",
        "- Embedding model: `@cf/baai/bge-base-en-v1.5` (768-dim)\n",
        "- Vector DB: Cloudflare Vectorize (REST API)\n",
        "- Input: PDFs under `../data/pdf_files`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/harshul/Development/RAG-Model/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Imports and setup\n",
        "import os\n",
        "import time\n",
        "import uuid\n",
        "import requests\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Any\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Optional progress bar\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except Exception:\n",
        "    def tqdm(x, **kwargs):\n",
        "        return x\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Environment configuration\n",
        "CLOUDFLARE_ACCOUNT_ID = os.getenv(\"CLOUDFLARE_ACCOUNT_ID\", \"<YOUR_ACCOUNT_ID>\")\n",
        "CLOUDFLARE_API_TOKEN = os.getenv(\"CLOUDFLARE_API_TOKEN\", \"<YOUR_API_TOKEN>\")\n",
        "VECTORIZE_INDEX_NAME = os.getenv(\"VECTORIZE_INDEX_NAME\", \"gst-rag-worker\")\n",
        "\n",
        "# Embedding model per Cloudflare docs\n",
        "CF_EMBEDDINGS_MODEL = \"@cf/baai/bge-base-en-v1.5\"  # 768-dim\n",
        "\n",
        "if any(v.startswith(\"<YOUR_\") for v in [CLOUDFLARE_ACCOUNT_ID, CLOUDFLARE_API_TOKEN]):\n",
        "    print(\"WARNING: Set CLOUDFLARE_ACCOUNT_ID and CLOUDFLARE_API_TOKEN in your environment or edit this cell.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6 PDF files to process\n",
            "\n",
            "Processing: Bill's_Windsurf_Shop_Invoice.pdf\n",
            "  ✓ Loaded 1 pages\n",
            "\n",
            "Processing: Amy's_Bird_Sanctuary_Invoice.pdf\n",
            "  ✓ Loaded 1 pages\n",
            "\n",
            "Processing: Interim-Presentation.pdf\n",
            "  ✓ Loaded 71 pages\n",
            "\n",
            "Processing: Cool_Cars_Invoice.pdf\n",
            "  ✓ Loaded 1 pages\n",
            "\n",
            "Processing: Dukes_Basketball_Camp_Invoice.pdf\n",
            "  ✓ Loaded 1 pages\n",
            "\n",
            "Processing: Diego_Rodriguez_Invoice.pdf\n",
            "  ✓ Loaded 1 pages\n",
            "\n",
            "Total documents loaded: 76\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PDF discovery and loading\n",
        "\n",
        "def process_all_pdfs(pdf_directory: str) -> List[Any]:\n",
        "    \"\"\"Load all PDFs found under a directory (recursive), returning LangChain Documents.\"\"\"\n",
        "    all_documents = []\n",
        "    pdf_dir = Path(pdf_directory)\n",
        "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
        "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
        "        try:\n",
        "            loader = PyPDFLoader(str(pdf_file))\n",
        "            documents = loader.load()\n",
        "            for doc in documents:\n",
        "                doc.metadata['source_file'] = pdf_file.name\n",
        "                doc.metadata['file_type'] = 'pdf'\n",
        "            all_documents.extend(documents)\n",
        "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error: {e}\")\n",
        "\n",
        "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
        "    return all_documents\n",
        "\n",
        "all_pdf_documents = process_all_pdfs(\"../data/pdf_files\")\n",
        "len(all_pdf_documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 76 documents into 93 chunks\n",
            "Example chunk preview:\n",
            "Invoice for Bill's Windsurf Shop\n",
            "Email: Surf@Intuit.com\n",
            "Invoice Details:\n",
            "Description Qty Unit Price Amount\n",
            "Design Service 1 $500.00 $500.00\n",
            "Consulting 2 $200.00 $400.00\n",
            "Installation 1 $300.00 $300.00\n",
            " ...\n",
            "{'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'source': \"../data/pdf_files/Bill's_Windsurf_Shop_Invoice.pdf\", 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': \"Bill's_Windsurf_Shop_Invoice.pdf\", 'file_type': 'pdf'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Chunking\n",
        "\n",
        "def split_documents(documents: List[Any], chunk_size=1000, chunk_overlap=200):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "    split_docs = text_splitter.split_documents(documents)\n",
        "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
        "    if split_docs:\n",
        "        print(\"Example chunk preview:\")\n",
        "        print(split_docs[0].page_content[:200], \"...\")\n",
        "        print(split_docs[0].metadata)\n",
        "    return split_docs\n",
        "\n",
        "chunks = split_documents(all_pdf_documents)\n",
        "len(chunks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cloudflare Workers AI Embeddings (REST client)\n",
        "\n",
        "class CFWorkersAIEmbeddings:\n",
        "    \"\"\"\n",
        "    Minimal client for Workers AI embeddings endpoint.\n",
        "    POST https://api.cloudflare.com/client/v4/accounts/{account_id}/ai/run/{model}\n",
        "    Body: {\"text\": \"<string>\"}\n",
        "    Returns: {\"result\": {\"data\": [[...]]}} or {\"data\": [...]}\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, account_id: str, api_token: str, model: str):\n",
        "        self.base = f\"https://api.cloudflare.com/client/v4/accounts/{account_id}/ai/run/{model}\"\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {api_token}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "\n",
        "    def embed_one(self, text: str, retries: int = 3, backoff: float = 1.5) -> np.ndarray:\n",
        "        payload = {\"text\": text}\n",
        "        last_err = None\n",
        "        for attempt in range(1, retries + 1):\n",
        "            try:\n",
        "                r = requests.post(self.base, headers=self.headers, json=payload, timeout=60)\n",
        "                if r.status_code == 200:\n",
        "                    data = r.json()\n",
        "                    vec = None\n",
        "                    if isinstance(data, dict) and \"result\" in data:\n",
        "                        result = data[\"result\"]\n",
        "                        if \"data\" in result and result[\"data\"]:\n",
        "                            first = result[\"data\"][0]\n",
        "                            vec = first if isinstance(first, list) else result[\"data\"]\n",
        "                    elif \"data\" in data:\n",
        "                        first = data[\"data\"][0] if isinstance(data[\"data\"], list) and data[\"data\"] and isinstance(data[\"data\"][0], list) else data[\"data\"]\n",
        "                        vec = first\n",
        "                    if vec is None:\n",
        "                        raise ValueError(f\"Unexpected response structure: {data}\")\n",
        "                    return np.array(vec, dtype=np.float32)\n",
        "                else:\n",
        "                    last_err = RuntimeError(f\"HTTP {r.status_code}: {r.text[:300]}\")\n",
        "            except Exception as e:\n",
        "                last_err = e\n",
        "            time.sleep(backoff ** (attempt - 1))\n",
        "        raise last_err\n",
        "\n",
        "    def embed_batch(self, texts: List[str]) -> np.ndarray:\n",
        "        vectors = []\n",
        "        for t in tqdm(texts, desc=\"Embedding with Workers AI\"):\n",
        "            vectors.append(self.embed_one(t))\n",
        "        return np.vstack(vectors)\n",
        "\n",
        "cf_embedder = CFWorkersAIEmbeddings(\n",
        "    account_id=CLOUDFLARE_ACCOUNT_ID,\n",
        "    api_token=CLOUDFLARE_API_TOKEN,\n",
        "    model=CF_EMBEDDINGS_MODEL,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cloudflare Vectorize client (REST)\n",
        "\n",
        "class CFVectorize:\n",
        "    \"\"\"\n",
        "    Minimal client for Cloudflare Vectorize upsert and query.\n",
        "    Upsert: POST /client/v4/accounts/{account_id}/vectorize/indexes/{index_name}/upsert\n",
        "    Query:  POST /client/v4/accounts/{account_id}/vectorize/indexes/{index_name}/query\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, account_id: str, api_token: str, index_name: str):\n",
        "        self.base = f\"https://api.cloudflare.com/client/v4/accounts/{account_id}/vectorize/indexes/{index_name}\"\n",
        "        # Only set Authorization; let 'requests' set Content-Type for JSON\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {api_token}\",\n",
        "        }\n",
        "\n",
        "    def upsert(self, vectors: List[dict]):\n",
        "        url = f\"{self.base}/upsert\"\n",
        "        r = requests.post(url, headers=self.headers, json={\"vectors\": vectors}, timeout=60)\n",
        "        if r.status_code != 200:\n",
        "            raise RuntimeError(f\"Vectorize upsert failed: HTTP {r.status_code}: {r.text[:300]}\")\n",
        "        return r.json()\n",
        "\n",
        "    def query(self, vector: List[float], top_k: int = 5, include_vectors: bool = False):\n",
        "        url = f\"{self.base}/query\"\n",
        "        body = {\"vector\": vector, \"topK\": top_k, \"includeVectors\": include_vectors}\n",
        "        r = requests.post(url, headers=self.headers, json=body, timeout=60)\n",
        "        if r.status_code != 200:\n",
        "            raise RuntimeError(f\"Vectorize query failed: HTTP {r.status_code}: {r.text[:300]}\")\n",
        "        return r.json()\n",
        "\n",
        "vectorize = CFVectorize(\n",
        "    account_id=CLOUDFLARE_ACCOUNT_ID,\n",
        "    api_token=CLOUDFLARE_API_TOKEN,\n",
        "    index_name=VECTORIZE_INDEX_NAME,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for 93 chunks using Workers AI model: @cf/baai/bge-base-en-v1.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding with Workers AI: 100%|██████████| 93/93 [00:26<00:00,  3.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings shape: (93, 768)\n",
            "Upserting 93 vectors to Vectorize index 'gst-regulations-index' ...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Vectorize upsert failed: HTTP 400: {\n  \"result\": null,\n  \"success\": false,\n  \"errors\": [\n    {\n      \"code\": 1005,\n      \"message\": \"vectorize.unknown_content_type\"\n    }\n  ],\n  \"messages\": []\n}\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     15\u001b[39m     vectors.append({\n\u001b[32m     16\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: vec_id,\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m: vec.astype(\u001b[38;5;28mfloat\u001b[39m).tolist(),\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: meta,\n\u001b[32m     19\u001b[39m     })\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUpserting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(vectors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m vectors to Vectorize index \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVECTORIZE_INDEX_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m upsert_result = \u001b[43mvectorize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m upsert_result\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mCFVectorize.upsert\u001b[39m\u001b[34m(self, vectors)\u001b[39m\n\u001b[32m     19\u001b[39m r = requests.post(url, headers=\u001b[38;5;28mself\u001b[39m.headers, json={\u001b[33m\"\u001b[39m\u001b[33mvectors\u001b[39m\u001b[33m\"\u001b[39m: vectors}, timeout=\u001b[32m60\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVectorize upsert failed: HTTP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.text[:\u001b[32m300\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r.json()\n",
            "\u001b[31mRuntimeError\u001b[39m: Vectorize upsert failed: HTTP 400: {\n  \"result\": null,\n  \"success\": false,\n  \"errors\": [\n    {\n      \"code\": 1005,\n      \"message\": \"vectorize.unknown_content_type\"\n    }\n  ],\n  \"messages\": []\n}\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings for chunks and upsert to Vectorize\n",
        "\n",
        "texts = [c.page_content for c in chunks]\n",
        "print(f\"Generating embeddings for {len(texts)} chunks using Workers AI model: {CF_EMBEDDINGS_MODEL}\")\n",
        "embeddings = cf_embedder.embed_batch(texts)\n",
        "print(\"Embeddings shape:\", embeddings.shape)\n",
        "\n",
        "# Prepare vectors payload with metadata\n",
        "vectors = []\n",
        "for i, (doc, vec) in enumerate(zip(chunks, embeddings)):\n",
        "    vec_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
        "    meta = dict(doc.metadata)\n",
        "    meta[\"doc_index\"] = i\n",
        "    meta[\"content_length\"] = len(doc.page_content)\n",
        "    vectors.append({\n",
        "        \"id\": vec_id,\n",
        "        \"values\": vec.astype(float).tolist(),\n",
        "        \"metadata\": meta,\n",
        "    })\n",
        "\n",
        "print(f\"Upserting {len(vectors)} vectors to Vectorize index '{VECTORIZE_INDEX_NAME}' ...\")\n",
        "upsert_result = vectorize.upsert(vectors)\n",
        "upsert_result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: quick similarity query to validate ingestion\n",
        "\n",
        "def query_similar(text: str, top_k: int = 3):\n",
        "    q_vec = cf_embedder.embed_one(text).astype(float).tolist()\n",
        "    res = vectorize.query(q_vec, top_k=top_k, include_vectors=False)\n",
        "    return res\n",
        "\n",
        "result = query_similar(\"What is in the invoice for Bill's Windsurf Shop?\", top_k=3)\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token verify status: 200\n",
            "{\n",
            "  \"result\": {\n",
            "    \"id\": \"358de5b477464356f9d512c2744f89c1\",\n",
            "    \"status\": \"active\"\n",
            "  },\n",
            "  \"success\": true,\n",
            "  \"errors\": [],\n",
            "  \"messages\": [\n",
            "    {\n",
            "      \"code\": 10000,\n",
            "      \"message\": \"This API Token is valid and active\",\n",
            "      \"type\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Index get status: 404\n",
            "{\n",
            "  \"result\": null,\n",
            "  \"success\": false,\n",
            "  \"errors\": [\n",
            "    {\n",
            "      \"code\": 3000,\n",
            "      \"message\": \"vectorize.index.not_found - Index name \\\"gst-regulations-index\\\"\"\n",
            "    }\n",
            "  ],\n",
            "  \"messages\": []\n",
            "}\n",
            "Upsert test status: 400\n",
            "{\n",
            "  \"result\": null,\n",
            "  \"success\": false,\n",
            "  \"errors\": [\n",
            "    {\n",
            "      \"code\": 1005,\n",
            "      \"message\": \"vectorize.unknown_content_type\"\n",
            "    }\n",
            "  ],\n",
            "  \"messages\": []\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Diagnostics: Verify Cloudflare credentials and Vectorize access\n",
        "import json\n",
        "\n",
        "CF_API_BASE = f\"https://api.cloudflare.com/client/v4\"\n",
        "COMMON_HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {CLOUDFLARE_API_TOKEN}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "# 1) Verify token\n",
        "verify_resp = requests.get(f\"{CF_API_BASE}/user/tokens/verify\", headers=COMMON_HEADERS, timeout=30)\n",
        "print(\"Token verify status:\", verify_resp.status_code)\n",
        "try:\n",
        "    print(json.dumps(verify_resp.json(), indent=2)[:800])\n",
        "except Exception as e:\n",
        "    print(\"Token verify parse error:\", e, verify_resp.text[:300])\n",
        "\n",
        "# 2) Check index exists\n",
        "index_url = f\"{CF_API_BASE}/accounts/{CLOUDFLARE_ACCOUNT_ID}/vectorize/indexes/{VECTORIZE_INDEX_NAME}\"\n",
        "idx_resp = requests.get(index_url, headers=COMMON_HEADERS, timeout=30)\n",
        "print(\"Index get status:\", idx_resp.status_code)\n",
        "try:\n",
        "    print(json.dumps(idx_resp.json(), indent=2)[:800])\n",
        "except Exception as e:\n",
        "    print(\"Index get parse error:\", e, idx_resp.text[:300])\n",
        "\n",
        "# 3) Try a minimal upsert (single small vector) to isolate auth/scopes\n",
        "try:\n",
        "    test_vec = {\n",
        "        \"id\": \"diag_test\",\n",
        "        \"values\": [0.0]*768,\n",
        "        \"metadata\": {\"_diag\": True},\n",
        "    }\n",
        "    upsert_url = f\"{CF_API_BASE}/accounts/{CLOUDFLARE_ACCOUNT_ID}/vectorize/indexes/{VECTORIZE_INDEX_NAME}/upsert\"\n",
        "    upsert_resp = requests.post(upsert_url, headers=COMMON_HEADERS, json={\"vectors\": [test_vec]}, timeout=30)\n",
        "    print(\"Upsert test status:\", upsert_resp.status_code)\n",
        "    print(upsert_resp.text[:800])\n",
        "except Exception as e:\n",
        "    print(\"Upsert test exception:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
